{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27506ee1-1743-4c39-97b8-05b77449fe7e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In this experiment, we will train the GPT-2 model using the BookCorpus dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba355ae2-1291-41e8-b0cb-2aad000a6894",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db6e44-7caa-4c5d-9bf9-33ffa8e2da32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color:Tomato;\"> Import the necessary Packages </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3bd6282-647c-430f-ac56-2a0137b0f63f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# used in the previous experiments\n",
    "from datasets import load_dataset,load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# for training\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "#for experiment tracking\n",
    "import wandb\n",
    "\n",
    "#common packages\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178fd67-5fe9-4364-9820-56e139d39622",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color:Tomato;\"> Dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf30633e-d25f-4259-9f04-aea2d0101491",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 74004228\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ds_full = load_dataset('bookcorpus',split='all')\n",
    "pprint(ds_full) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec896259-edc8-46ba-afac-9ea4602a096a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The dataset contains 74 million sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f402be86-1a2d-4b15-8973-c8a1d9250e89",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The dataset contains about 1 billion words (**Exercise:** write code to get the exact number.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd9608-d3c3-46e5-b35b-9357082f8478",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "There are 71,598 samples that contain a single word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a71faf-f7e2-4852-bd30-76645996244d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The context length of the gpt-2 model is 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ea49f-0a15-44d8-a6d1-15041b90d470",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "There are 50 samples that are larger than the context length of the model (with the largest sample containing 65,852 elements)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f257c3-d6e6-4cae-b36b-1ba46d19b99f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Let us randomly select one million samples from the 74 million to better understand the distribution, excluding the 50 largest samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec742be0-394c-4c21-b2fb-9787475fc33b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this cell will be hidden from the presentation\n",
    "with open('misc/bc_stats.json','r') as f:\n",
    "    bc_stats = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd475b4-fcff-45ca-899e-5ebb6a0dfe3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "sorted_len = bc_stats['len_samples_sorted']\n",
    "bins = np.unique(sorted_len)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(random.sample(sorted_len[0:-50],k=10**6),bins=bins[0:150])\n",
    "plt.xlabel('Sequence length')\n",
    "plt.ylabel('count')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04161ecf-154f-44e6-bd42-9c2eac87c9a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The length of a majority of the samples is far less than 60 and the average length is 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3b452-e187-4ac8-af02-95143a749435",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color:Tomato;\"> Tokenization </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeab982-334b-4ce0-9e05-2b000fed79b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The next step is to tokenize the samples using the `PreTrainedTokenizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b9ff5-e335-4aff-9920-02a1b10b7def",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We can use the `hopper` tokenizer that we have trained in the previous experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "908bc1cf-dbc6-49e5-a373-c61f8e53bc37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='../Week-2/hopper', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "hopper_tokenizer = AutoTokenizer.from_pretrained('../Week-2/hopper')\n",
    "print(hopper_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891fedcf-cd43-4013-9860-a409913d53e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Let us pass a batch of samples with padding enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b219020d-4c29-400f-b466-84e30ba70463",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2462, 19, 149, 277, 162, 6456, 422, 131, 1559, 536, 19, 2301, 201, 177, 9774,\n",
      "  21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0],\n",
      " [212, 297, 289, 456, 208, 46, 20830, 1420, 214, 4099, 1171, 139, 11126, 21, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0],\n",
      " [178, 206, 337, 7656, 14, 64, 1147, 303, 174, 503, 214, 2363, 2310, 21, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0],\n",
      " [149, 14, 49, 946, 131, 3760, 880, 375, 3446, 19, 3766, 149, 166, 46, 545,\n",
      "  1185, 200, 131, 61, 93, 17794, 19, 212, 201, 2596, 9302, 19, 1050, 201, 163,\n",
      "  3186, 19, 5696, 166, 2270, 5194, 138, 717, 178, 278, 2596, 21]]\n"
     ]
    }
   ],
   "source": [
    "bs = 4 # batch_size\n",
    "model_inputs = hopper_tokenizer(ds_full[0:bs]['text'],padding=True)\n",
    "pprint(model_inputs['input_ids'],compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7df779-dbbc-4dfe-9fa1-6e0b90a6b367",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "What happens if a batch contains a sample of length 1 and 50?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a4fbeb-afdd-49c5-8a96-01c1945e03ac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We append 49 zeros to that shortest sample! It is a waste of compute (while pretraining)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2eea5-4729-4118-a851-b17f536a9d13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Moreover, the samples in the dataset  maintain continuity with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a3124fb-b692-4314-adae-faa57e2ba5fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'he loved sitting between her brothers on the couch and watching tv .',\n",
      " 1: 'while it was good that he had so many male role models , she only hoped '\n",
      "    \"he had n't inherited too much of his father 's personality .\",\n",
      " 2: 'after megan watched them disappear in the crowd of family and friends '\n",
      "    'waiting in the church alcove , she bypassed everyone by turning right and '\n",
      "    'heading down the hallway .',\n",
      " 3: 'at the last door on the right , she knocked .',\n",
      " 4: \"`` it 's me , megan . ''\",\n",
      " 5: \"emma 's best friend , casey , answered the door .\",\n",
      " 6: \"`` well , if it is n't the fairy godmother , '' she mused with a grin .\",\n",
      " 7: 'after megan stepped inside , casey threw her arms around her .',\n",
      " 8: \"megan had only met her a few times , but it was hard not liking emma 's \"\n",
      "    'vivacious and outgoing friend .',\n",
      " 9: \"casey 's long brown hair was pulled back in a lose knot , and she wore a \"\n",
      "    'demure black slip dress and heels .'}\n"
     ]
    }
   ],
   "source": [
    "pprint({id:example for id,example in enumerate(ds_full[ ]['text'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7397715-c4e3-4659-8506-c335241e899c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Therefore, to use the available compute effectively, we can concatenate the samples so that the length of the concatenated sample equals the model's context length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc518d1-506b-44b1-80e7-ced101ea3adf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "It requires us to tokenize the samples and concatenate the tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea76a4-4670-44c3-a129-3b61ef76be07",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Therefore, we do not need to use the `padding` token for pretraining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c2264-5c28-4344-bbf4-24024cd410d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Let's use the `gpt2 tokenizer` (uses Bytelevel BPE). We can simply load it from the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f45cc8b8-b759-4f1c-ad12-90385b72fcc4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlp/.dlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac46fe56-bdae-45ad-bfdb-2f793d156964",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Note the details such as `vocab_size`, `model_max_length` and `special_tokens` (all the special tokens expected by HF `PreTrainedTokenizerFast` are mapped to `<|endoftext|>` token that was originally used by the gpt2 tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144bab7f-0d6d-4782-b00d-1dd73d01dff7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "The parameter `padding_side` is set to `right`, but since no padding token is used, we should add a padding token to avoid errors from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f392464-d111-48c5-9dfa-ceb8bf1ef4eb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = '<|endoftext|>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69958ce7-015e-47fe-b256-17007a4f2df0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Define a **mapping** function that takes a batch of samples and returns `input_ids` and `attention_mask` such that the length of `input_ids` is 1024 for all samples. (Take this as an exercise.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a971bbed-2433-4547-bcaf-a845178be0fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We did this and stored it as a separate dataset. Now, let's load it from the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e0283c4-75e8-4dfe-b0de-5e3af014a9d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_chunked = load_from_disk('data/BC_Chunked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf3a04cc-0dcb-4cb5-9765-6d71a3dcfa65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask'],\n",
      "    num_rows: 1055117\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds_chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc2562-7058-4253-a801-e18136d7e2a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Quick check:** <br>\n",
    "1. There are 1,055,117 samples.\n",
    "2. Each sample has a length of 1024\n",
    "3. Therefore, the total number of tokens is $1055117 \\times 1024 = 1.08$ billion tokens.\n",
    "4. This confirms that no extra tokens were added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31273060-8799-4636-9506-06f1d366f3b7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color:Tomato;\"> Data Loader </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f73ed-f58a-4d25-be14-5330a3a69623",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Split the dataset into train and test splits (setting seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e835e8b-65aa-4049-83de-431f5982e221",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask'],\n",
      "        num_rows: 1047731\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask'],\n",
      "        num_rows: 7386\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ds_split = ds_chunked.train_test_split(test_size=0.007,seed=42)\n",
    "print(ds_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac30a4-f26e-4e49-a231-388d96b193bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Recall that the `DataLoader` prepares the data for the model. The prepartion includes shuffling the data, **collating** a batch of samples with or without padding, and distributing it across multiple gpus or nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8bf4f-519c-46de-8e0f-1bad1bb75333",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The collate function varies based on the model's training objective (e.g., CLM, MLM, PLM). Therefore, Hugging Face provides several commonly used collate functions: <br>\n",
    "1. DataCollatorForSeq2Seq\n",
    "2. DataCollatorForLanguageModelling\n",
    "3. DefaultDataCollator\n",
    "\n",
    "[Doc](https://huggingface.co/docs/transformers/main/main_classes/data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b1a2d00-b9aa-44b4-b279-31274d6ffdce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer,mlm=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f0fc44-76eb-458d-a5d4-1612af77cc6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "HF uses this `data_collator` function internally. However, letâ€™s take a closer look at what it does using the `DataLoader` from PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aba9dd40-7f43-459c-a622-348be5def3f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d1d29a-baf0-4cd1-ac76-12eb86a41980",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=ds_split['train'],\n",
    "                        collate_fn=data_collator,\n",
    "                        batch_size=4,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b8405ac-bd11-4f42-b35b-ea33d151b27b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]),\n",
      " 'input_ids': tensor([[13769,   644,   262,  ...,  1323,   837,  8591],\n",
      "        [14262,   616, 17841,  ...,   423,   345, 21256],\n",
      "        [17007,   873,   262,  ...,   302,   276,   705],\n",
      "        [  503,   286,   262,  ...,   764,  7091,   550]]),\n",
      " 'labels': tensor([[13769,   644,   262,  ...,  1323,   837,  8591],\n",
      "        [14262,   616, 17841,  ...,   423,   345, 21256],\n",
      "        [17007,   873,   262,  ...,   302,   276,   705],\n",
      "        [  503,   286,   262,  ...,   764,  7091,   550]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    pprint(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9103779-f938-42fd-8fa3-911592551eb7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "1. It returns (by default) the attributes as PyTorch `tensor` objects instead of Python `lists`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb1fd77-f940-4343-b858-70a5b8b66212",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "2. It also returns the labels; for CLM, the `input_ids` serve as the labels with a shift (the shift happens in the training loop)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da84352f-e6f2-47f8-a8d2-2cf53f8c6886",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color:Tomato;\"> Initialize the Model </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d17dd6-b1b4-40e2-8c4f-2763e817172c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We can build the model in PyTorch and Wrap it using HF `PreTrainedConfig` class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c1e5f-14e1-4c19-beac-09b7e62dc4bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "HF already has the GPT architecture built in, with over 350,000 models available in the hub. We can load these models and **modify the configuration** to customize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2c640bb-c689-4d58-b6bd-efbad288453b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.44.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configuration = GPT2Config()\n",
    "pprint(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f316a28c-d906-45df-ba09-4661b083bcaf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Now, we can build the model with the Language Modelling head with the weights **initialized randomly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b52143c4-4a6c-477e-bcf2-f26b1759a5be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7acc6202-6152-4c4f-ba22-e99d95ad9701",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3c31e3-e782-488e-bcf6-20507faf44d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Quick Check:** vocab size: 50257, embedding dim: 768, learnable position embedding (pe), uses Scaled Dot Product Attention (SDPA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969e19f6-063c-47c4-aefd-f40d8dadce45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Finally, let's count the number of Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0540169-cc4b-49f8-a2d2-2634c44c7f79",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters:124.44M\n"
     ]
    }
   ],
   "source": [
    "num_parameters = 0\n",
    "for param in model.parameters():    \n",
    "    num_parameters += param.numel()\n",
    "print(f'Number of Parameters:{num_parameters/10**6:.2f}M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5597d0d2-f1eb-4e37-8e1a-9ea34cd42acc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color:Tomato;\"> Train the Model </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaec482-0201-4a69-b31a-3c67841177e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Training a model requires the following sequence of operations as shown in the figure below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fafdf1-b933-4364-aea1-132335390372",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Arunprakash-A/Modern-NLP-with-Hugging-Face/refs/heads/main/Notebooks/images/training_loop.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32949427-e70f-42b8-8b18-69a61d78961d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "1. Get a batch of samples.\n",
    "2. Make predictions.\n",
    "3. Compute loss.\n",
    "4. Compute gradients.\n",
    "5. Choose a learning rate scheduler.\n",
    "6. Choose an optimizer and set its hyperparameters.\n",
    "7. Update the weights.\n",
    "8. repeat until a criterion is met (convergence, compute credits, time,etc.,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb22161-85e5-4c05-b92d-3508d299c822",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Apart from these steps, we may need to set parameters for [efficient training](https://huggingface.co/docs/transformers/v4.29.1/en/perf_train_gpu_one) strategies in both single and multi-GPU settings, as well as perform experiment tracking and logging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2466df-7dfb-45ab-b92a-dec7336c46c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We use wandb for experiment tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a522606-c002-4cb3-98fd-f7dcdb26b69f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "wandb.init(\n",
    "    project=\"DLP-GPT2-Node-1\",     \n",
    "    config={\n",
    "        \"batch_size\":16,        \n",
    "        \"dataset\": \"Bookcorpus-74M\",\n",
    "    },\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751ac83-23b2-413a-8cb0-98250c28b9a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "All these training complexities are managed by two functions from the Transformers library: `TrainingArguments` and `Trainer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa81302-7b50-4664-b08e-e10cf8b82bde",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Let's look at a few important arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4afe7f9-40ea-4c72-afed-09841cbddf58",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "`eval_steps`: Compute validation loss every 500 steps.<br>\n",
    "`per_device_train_batch_size`: 8 samples (requires about 27 GB of memory). <br>\n",
    "`per_device_eval_batch_size` : 8 samples (can be larger since gradients are not computed).<br>\n",
    "`tf32`: whether or not to use the tf32 datatype (for matrix multiplication) to increase computation speed.<br>\n",
    "`bf16`: whether or not to use the bf16 (high dynamic range) for mixed precision training.<br>\n",
    "`fp16`: whether or not to use the fp16 (low dynamic range) for mixed precision training. <br>\n",
    "`num_train_epochs`: 1 (budget is the bottleneck)<br>\n",
    "`save_steps`: Store model checkpoints every 1000 steps (after processing 8 million tokens).<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "704291aa-fb8e-4f44-82e0-8a6aac04b8ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments( output_dir='out',\n",
    "                                  eval_strategy=\"steps\",\n",
    "                                  eval_steps=500,                                  \n",
    "                                  num_train_epochs=1,\n",
    "                                  per_device_train_batch_size=8,\n",
    "                                  per_device_eval_batch_size=8,\n",
    "                                  bf16=False,\n",
    "                                  fp16=False,\n",
    "                                  tf32=False,\n",
    "                                  adam_beta1=0.9,\n",
    "                                  adam_beta2=0.999,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  weight_decay=0.01, \n",
    "                                  gradient_accumulation_steps=1,\n",
    "                                  logging_strategy=\"steps\",\n",
    "                                  logging_steps = 500,\n",
    "                                  save_steps=1000, \n",
    "                                  save_total_limit=15,                                  \n",
    "                                  report_to='wandb',                                  \n",
    "                                 )                               \n",
    "                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642c0af-3909-45ad-bf66-366459151dfd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Finally, let's use the `Trainer` API to set up the entire training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a2315f2-e173-46bf-92a1-f0c931e0007d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                 args = training_args,\n",
    "                 train_dataset=ds_split[\"train\"],\n",
    "                 eval_dataset= ds_split[\"test\"],\n",
    "                 data_collator = data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5833996e-3d5a-458e-9466-d08e7adad214",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Just call `.train()` method, sit back, and watch for OOM error :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c206648-42b6-48e3-9a81-3d88ad6c74fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "results = trainer.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d31c8f-ff58-4593-a97f-1faabaf28757",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Arunprakash-A/Modern-NLP-with-Hugging-Face/refs/heads/main/Notebooks/images/sample_out.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64543a-a447-45a6-a7a5-ae1a59089d12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We ran the model on three different GPUs: <br>\n",
    "1. V100 with **32 GB** (no support for: tf32, bf16)\n",
    "2. 2xL4 **48 GB** (supports bf16,tf32) \n",
    "3. A node with A100 **80 GB** (supports bf16, tf32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0826c8bc-74f3-4493-9531-add5c17f1c6d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color:Tomato;\"> Efficient Training </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd8b1b-ba41-404e-a0e4-5fb708d84eea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We know that increasing the batch size helps achieve faster convergence. However, for a given GPU, how can we increase the batch size without raising an OOM error?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d0830-1d7e-4a2a-8a9a-bc56a2a84d8d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "How can we increase computation speed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3935ca4-b977-47b0-b2c9-9168f848e60f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Setting following arguments help us achieve these objectives <br>\n",
    "`tf32`: whether or not to use the tf32 datatype (for matrix multiplication) to increase computation speed.<br>\n",
    "`bf16`: whether or not to use bf16 (high dynamic range) for mixed precision training.<br>\n",
    "`fp16`: whether or not to use fp16 (low dynamic range) for mixed precision training. <br>\n",
    "`gradient_accumulation_steps`: Use gradient accumulation for increased batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750370e4-3dc1-41b6-8ab5-d36f3fbd1ba9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We will not go into the details; you may refer to this [page]((https://huggingface.co/docs/transformers/v4.29.1/en/perf_train_gpu_one)) on HF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42190397-8a5c-4c12-a1a4-19fd57b5797a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "However, we have used a combination of these arguments to demonstrate how they are helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf58fb1-49ef-4b44-9861-a3023e922258",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color:Tomato;\"> Experiment Tracking with WandB </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06f96694-c969-4df2-881a-ebe31659b327",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"https://wandb.ai/a-arun283-iit-madras/DLP-GPT2-Node-1/reports/DLP-PreTraining-GPT-2--Vmlldzo5NTgxMTUx\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7efb79a66230>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"https://wandb.ai/a-arun283-iit-madras/DLP-GPT2-Node-1/reports/DLP-PreTraining-GPT-2--Vmlldzo5NTgxMTUx\", width=\"100%\", height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b080e6b2-97d8-4d08-82af-cce9f1d62ccf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color:Tomato;\"> Text Generation </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e1580-6246-4cf5-85c4-5128de1fc54a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We can load the model with the pretrained weights, which now come from different checkpoints stored in the `out/checkpoint-xxxx/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe8d4391-89fd-49a5-8bf9-85f05f9830cf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#after seeing 128(bs)*1024(n_ctxt)*1000(steps)=131 million tokens\n",
    "model =GPT2LMHeadModel.from_pretrained('out/checkpoint-1000/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b37f2-150e-4041-8c04-c6b37f1a3cee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Note:** We must ensure that the input to the model is a PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0bb789f-3c51-4fa0-b209-9e61ea30998e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[1616,  514,  423,  257, 1257, 1909,   13, 1867,  466,  345,  910,   30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"let us have a fun today. What do you say?\"\n",
    "inputs = tokenizer(prompt,return_tensors='pt',padding=True) # return torch tensor\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb0472e-424d-45f5-ab54-68f8cfae376c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "* Generate `100` tokens\n",
    "* Use `top-p` decoding strategy. Refer to Week 3 of [Introduction to Large Language Models](http://www.cse.iitm.ac.in/~miteshk/llm-course.html) for more information on various decoding strategies.\n",
    "* You may visit the [documentation](https://huggingface.co/docs/transformers/v4.45.1/en/generation_strategies#text-generation-strategies) to explore all available decoding strategies in HF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c0e1c4-6e75-4b63-9887-f501539fa296",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We can call `.generate()` method of the model and pass the inputs (**inputs unpack all the keys (`input_ids`,`attention_mask`,..))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e325493-748f-4a16-add3-dd9ed47c04ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1616,   514,   423,   257,  1257,  1909,    13,  1867,   466,   345,\n",
      "           910,    30, 10148,    72,   531,   837,  7559,   475,   345,   765,\n",
      "           284,   307,   257,  1310,   517,   546,   340,   764,    72,   466,\n",
      "           299,   470,   761,   284,   651,   284,   766,   340,   764, 10148,\n",
      "           258,   705,    76,   407,   257,  1256,   286,   262,   835,   764,\n",
      "           258,   373,   257,  1310,   517,   764, 15506,   340,   373,   257,\n",
      "          1256,   764, 10148, 15506,   326,   345,   466,   299,   470,   307,\n",
      "           257,  1310,   764, 10148, 15506,   345,   547,   299,   470,   765,\n",
      "           284,   262,   938,  1755,   764, 10148, 15506,  1312,   705,   297,\n",
      "           307,   257,  1256,   286,   616,  1204,   764, 10148,    72,   531,\n",
      "           837,   290,   788,   339,   750,   299,   470,   765,   284,   262,\n",
      "          2156,   764]])\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**inputs, max_new_tokens=100, do_sample=True, top_k=10, top_p=0.95)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7507644-3575-49d0-abc0-a39a91f4445e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "First, we need to convert the predicted token_ids back to tokens, and then to words using the tokenizer's decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62014bf2-f6af-4556-9c7f-dea329b1bf90",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"let us have a fun today. What do you say? ''i said, `` but you want to be a little more about it.i don't need to get to see it. ''he'm not a lot of the way.he was a little more.`` it was a lot. ''`` that you don't be a little. ''`` you weren't want to the last night. ''`` i 'll be a lot of my life. ''i said, and then he didn't want to the house.\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab31fe4a-f4f2-4703-bea7-799b7938356f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Checkpoint-4000:** (after seeing 520 million tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d486618d-2e12-4a14-bd48-a1739a6cdcb3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"let us have a fun today. What do you say? ''`` what's going on? ''i'm a little bit, but it's all i'm sure i'm not going to know.`` what's going on? ''i ask, trying to get up with it.`` don't think of anything, '' i say, looking at him.`` i'm not going to be a big deal. ''he's still trying to make me feel the way out of my mouth.`` and i '\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =GPT2LMHeadModel.from_pretrained('out/checkpoint-4000/')\n",
    "prompt = \"let us have a fun today. What do you say?\"\n",
    "inputs = tokenizer(prompt,return_tensors='pt',padding=True) \n",
    "outputs = model.generate(**inputs, max_new_tokens=100, do_sample=True, top_k=10, top_p=0.95)\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ace163-024d-4fed-88b8-f784681ad8b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Checkpoint-8000:** (after seeing 1 billion tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a959370f-58d7-4cde-9827-fccb3eb4495a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"let us have a fun today. What do you say? ''`` i know, '' i answered.`` i don't know how to start with you. ''`` i'm not going to have to tell you the truth. ''i nodded, trying to make a face of a smile.i didn't care if she was being an ass**le.i knew how long i 'd been in my life when i 'd been a man, and i had to make the right thing up to her.`` what? ''`` what\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =GPT2LMHeadModel.from_pretrained('out/checkpoint-8185/')\n",
    "prompt = \"let us have a fun today. What do you say?\"\n",
    "inputs = tokenizer(prompt,return_tensors='pt',padding=True) \n",
    "outputs = model.generate(**inputs, max_new_tokens=100, do_sample=True, top_k=10, top_p=0.95)\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f5ed1-e37c-44b9-adfe-d7e3efb936bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
